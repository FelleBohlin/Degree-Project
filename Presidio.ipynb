{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd6b6663",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aef425ef-94e7-409e-8184-a8272d46f23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\felix\\Anaconda3\\python.exe: No module named spacy\n"
     ]
    }
   ],
   "source": [
    " ! python -m spacy download sv_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4fb6bb4-023e-4cb8-9e22-cbd902be070c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import os\n",
    "import re\n",
    "import spacy\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from langchain_experimental.data_anonymizer import PresidioAnonymizer\n",
    "from langchain_experimental.data_anonymizer import PresidioReversibleAnonymizer\n",
    "from langdetect import detect, LangDetectException\n",
    "from faker import Faker\n",
    "from langchain.schema import runnable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d927f14c-963c-4b4c-bf32-8b7f41d2244c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "560d3d8c-4c92-46d9-9008-6f21ab3f5e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]\n",
    "if OPENAI_API_KEY is None:\n",
    "    raise ValueError(\"OPENAI_API_KEY does not exist, add it to env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0189098c-9690-4dd3-8c58-be3dcda843a3",
   "metadata": {},
   "source": [
    "This cell uses the OpenAI GPT-4 API to generate pre-marked flowing-text training data.\n",
    "The generated texts include dummy data of personal identifiable information (PII). Each instance of sensitive information within the text is clearly marked according to predefined tags.\n",
    "\n",
    "**Functions of the code:**\n",
    "- **Folder Creation**: Automatically creates a folder for output if it does not already exist.\n",
    "- **Data Generation**: Utilizes OpenAI's GPT-4 to craft text strings embedded with marked personal information.\n",
    "- **File Output**: Saves each generated text string as a `.txt` file within the designated output folder.\n",
    "- **PII Tagging**: Demonstrates how to programmatically mark personal information within text using specific XML-like tags for different data types.\n",
    "\n",
    "**Sensitive Data Includes:**\n",
    "- Names, phone numbers, addresses, email addresses, numeric identifiers (e.g., member numbers, bank account numbers), and credit card\n",
    "\n",
    "**Note**\n",
    "If text files already exist in the folder, please delete them before generating new ones. details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "59ae5f8c-ea3c-45a6-a8c6-df4c149ddab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texter genererade och sparade.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "#Enter the name of the folder where the texts will be generated.\n",
    "#Creates a new folder if one does not exist\n",
    "output_folder = \"generated_texts\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "llm = OpenAI(openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "output_string = \"\"\n",
    "for i in range(50):\n",
    "    prompt = f\"\"\"\n",
    "    Jag skapar output träningsdata som ska användas för att träna min modell.\n",
    "    Användandet ska vara till att generera en löpande text som ska innehålla dummy data av påhittad personlig känslig information.\n",
    "    Varje gång känslig information genereras ska den markeras tydligt i texten. Endast en löpande text, ingen annan output.\n",
    "    \n",
    "    Markeringsformat för känslig information:\n",
    "    <name> för namn, <phone> för telefonnummer, <address> för adresser, <email> för e-postadresser, <id> för numeriska/alfanumeriska identifierare, och <credit_card> för kreditkortsinformation.\n",
    "    Innan och efter markeringen lämna mellanrum.\n",
    "    \n",
    "    Exempel på hur texten ska formuleras:\n",
    "    'Jag träffade en person som hette <name> Johan Svensson </name> igår. Han gav mig sitt telefonnummer <phone> 123-456-7890 </phone> samt hans e-postadress <email> johan.svensson@gmail.com </email>.'\n",
    "    \n",
    "    Personlig känslig information inkluderar:\n",
    "    Person/Namn - Detta inkluderar förnamn, mellannamn, efternamn eller hela namn på individer.\n",
    "    Telefonnummer - Alla telefonnummer, inklusive avgiftsfria nummer.\n",
    "    Adress - Kompletta eller partiella adresser, inklusive gata, postnummer, husnummer, stad och stat.\n",
    "    E-post - Alla e-postadresser.\n",
    "    Numeriskt Identifierare - Alla numeriska eller alfanumeriska identifierare som ärendenummer, medlemsnummer, biljettnummer, bankkontonummer, IP-adresser, produktnycklar, serienummer, spårningsnummer för frakt, etc.\n",
    "    Kreditkort - Alla kreditkortsnummer, säkerhetskoder eller utgångsdatum.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = openai.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "      {\"role\": \"system\", \"content\": \"Du är en hjälpful assistent, designad för att generera text data.\"},\n",
    "      {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    )\n",
    "    res = response.choices[0].message.content\n",
    "    file_path = os.path.join(output_folder, f\"text_{i+1}.txt\")\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(res)\n",
    "\n",
    "print(\"Texter genererade och sparade.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff63a87-33cd-4569-bcee-bc0f80aefa4e",
   "metadata": {},
   "source": [
    "Creates arrays of the PII in the texts wich will be used to test models comparing if the PII in these arrays still exist in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c951439-209c-4294-97c3-2df6ef9e5dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PII contents in text_1.txt: [' Adam Lindström ', ' 076-555-7890 ', ' Berggränd 29, 140 34 Stockholm ', ' Sara Eriksson ', ' 072-123-4567 ', ' Trädkojvägen 7, 660 60 Malung ', ' Carl Gustafsson ', ' carl.gustafsson@gmail.com ', ' CG123456J ', ' Mikael Blomqvist ', ' 079-654-3210 ', ' mikael.blomqvist@hotmail.com ', ' Techvägen 3, 753 20 Uppsala ', ' Anna Berg ', ' 070-999-8888 ', ' anna.berg@yahoo.com ', ' 5555-5555-5555-5555 ']\n",
      "PII contents in text_10.txt: [' Isabella Larsson ', ' 0768-123-456 ', ' isabella.larsson@samplemail.com ', ' Rörstrandsgatan 21A, 113 55 Stockholm ', ' IT789456 ', ' 1234-5678-9012-3456 ']\n",
      "PII contents in text_11.txt: [' Anna Johansson ', ' 070-123-4567 ', ' Storgatan 54, 12345 Stadsville ', ' anna.johansson@domain.se ', ' AJ7659 ', ' 4564-2359-4839-1234 ', ' Erik Olsson ', ' 072-789-0123 ', ' Smågatan 34, 67890 Landsville ', ' erik.olsson@web.se ', ' EO1239 ', ' 1234-5678-9101-1121 ']\n",
      "PII contents in text_12.txt: [' Karin Lindgren ', ' 070-123-1698 ', ' karin.lindgren@gmail.com ', ' Kungsgatan 15, 111 43 Stockholm ', ' KL-17294 ', ' kreditkortsnummer ']\n",
      "PII contents in text_13.txt: [' Emma Karlsson ', ' Södergatan 23, 12345 Stockholm ', ' 012-345-6789 ', ' emma.karlsson@hotmail.com ', ' 987AGH678 ', ' 4567-8912-3456-7890, 07/24, 123 ', ' Jakob Nilsson ', ' Södergatan 24, 12345 Stockholm ', ' PN4567 ', ' 987-654-3210 ', ' jakob.nilsson@gmail.com ', ' 1234-5678-9123-4567, 12/23, 321 ']\n",
      "PII contents in text_14.txt: [' Anna Andersson ', ' 098-765-4321 ', ' Oskar Pettersson ', ' Grönvägen 5, 12345 Stockholm ', ' PKG5643XYZ ', ' Linnea Karlsson ', ' linnea.karlsson@maildomain.com ', ' Erik Johansson ', ' Blomstergatan 23, 67890 Göteborg ', ' MEMB12345 ', ' Oliver Nilsson ', ' oliver.nilsson@maildomain.com ', ' +1-223-334-4455 ', ' Ida Bergström ', ' CAB1234 ', ' 234-567-8901 ', ' Emma Gustavsson ', ' Smågatan 12, 34567 Lund ', ' emma.gustavsson@maildomain.com ']\n",
      "PII contents in text_15.txt: [' Anna Andersson ', ' 070-123-4567 ', ' Tranbärsvägen 12, 12345, Uppsala ', ' anna.andersson@mail.com ', ' A123B456 ', ' 4567 1234 5678 9012, Utgångsdag: 01/24, CVV: 123 ']\n",
      "PII contents in text_16.txt: [' Anna Karlsson ', ' Storgatan 25, 12345 Stockholm ', ' 070-123-4567 ', ' anna.karlsson@example.com ', ' XYZ123 ', ' 1234-5678-9012 ', ' Anna Karlsson ', ' 1234 5678 9012 3456 ']\n",
      "PII contents in text_17.txt: [' Lisa Ström ', ' 070-987-6543 ', ' Lisa.strom@gmail.com ', ' Högbergsgatan 12, 11852 Stockholm ', ' Jonas Berg ', ' 072-456-7890 ', ' Martin Karlsson ', ' X293LA ', ' 073-890-1234 ', ' Kungsgatan 15, 11143 Stockholm ', ' Anna Nilsson ', ' Anna.nilsson@consultant.com ', ' Mäster Samuelsgatan 60, 11121 Stockholm ', ' Erik Lund', ' 1234 5678 9123 4567 ']\n",
      "PII contents in text_18.txt: [' Anna Karlsson ', ' Kungsportsavenyen 1, 411 36 ', ' 0712-345678 ', ' anna.karlsson@example.com ', ' 987654321 ', ' Olof Petersson ', ' Brunnsvägen 4, 123 45 Stockholm ', ' 0735-123456 ', ' olof.petersson@example.com ', ' 162738492 ', ' Frida Gustavsson ', ' 0796-987654 ', ' Konstvägen 7, 567 89 Malmö ', ' frida.gustavsson@example.com ']\n",
      "PII contents in text_19.txt: [' Alice Lindström ', ' 098-765-4321 ', ' alice.lindström@webmail.com ', ' Storgatan 23, 12345 Stockholm ', ' 123456789 ', ' 4567-8901-2345-6789 ']\n",
      "PII contents in text_2.txt: [' Anna Eriksson ', ' 0789-567-123 ', ' anna.eriksson@hotmail.com ', ' John Doe ', ' john.doe@gmail.com ', ' 123-456-7890 ', ' Olof Persson ', ' Birgitta Gatu 34, 12345 Stockholm ', ' XGY12345Z ', ' 456-789-1230 ', ' klara.bokklubben@yahoo.com ', ' Gustav Lind ', ' 1234 5678 9123 4567 ', ' 789 ', ' 12/23 ']\n",
      "PII contents in text_20.txt: [' Erik Nilsson ', ' 070-123-4567 ', ' erik.nilsson@mail.com ', ' Solgatan 9, 123 45, Stockholm ', ' ABC123 ', ' kreditkortsinformation ']\n",
      "PII contents in text_21.txt: [' Karolina Johansson ', ' Rosenstigen 25, 14252 Skogås ', ' 072-254-8963 ', ' karolina.johansson@post.se ', ' Visa kort ', ' ABC-123-DIJ ']\n",
      "PII contents in text_22.txt: [' Sofia Andersson ', ' 070-123-4567 ', ' Karl Jonsson ', ' karl.jonsson@hotmail.com ', ' Lisa Karlsson ', ' Storgatan 15, 12345 Stockholm ', ' Erik Olsson ', ' M123456 ', ' Anna Nilsson ', ' 1234 5678 9012 3456 ']\n",
      "PII contents in text_23.txt: [' Olivia Nilsson ', ' Solrosstigen 31, 75365 Uppsala ', ' 073-555-1234 ', ' olivia.nilsson@gmail.com ', ' FIT123567890 ', ' Benjamin Nilsson ', ' Lärkvägen 10, 97341 Luleå ', ' benjamin.nilsson@hotmail.com ', ' 091-123-4567 ', ' 1234-5678-9012-3456 ', ' Elisabeth Nilsson ', ' Krokusgatan 45, 84134 Ånge ', ' 060-789-0123 ', ' BK567899012 ', ' elisabeth.nilsson@yahoo.com ']\n",
      "PII contents in text_24.txt: [' Lisa Johansson ', ' 071-234-5678 ', ' lisa.johansson@hotmail.com ', ' Bagargatan 23, 43210 Göteborg ', ' LJ3451 ', ' 4856-1234-5678-9012 ', ' Samuel Eriksson ', ' Prinsgatan 85, 11211 Stockholm ', ' samuel.eriksson@företaget.se ', ' 073-789-1234 ', ' 5524-5678-9012-3456 ', ' SE345BC ']\n",
      "PII contents in text_25.txt: [' Lisa Johansson ', ' 076-941-5423 ', ' Gjutarvägen 20, 12145 Stockholm ', ' lisa.johansson@mail.com ', ' LJ4532KO ', ' 4358 5678 1234 5678 ']\n",
      "PII contents in text_26.txt: [' Anna Strömberg ', ' 070-123-4567 ', ' anna.stromberg@example.com ', ' Carl Johansson ', ' Snickargatan 25, 12345, Stockholm ', ' carl.johansson@example.com ', ' Oskar Berg ', ' Blomstervägen 17, 67890, Göteborg ', ' 076-234-5678 ', ' oskar.berg@example.com ', ' AB123-456CD ', ' 1234 5678 9012 3456 ', ' 789 ', ' 12/24 ']\n",
      "PII contents in text_27.txt: [' Anna Johansson ', ' 098-765-4321 ', ' Sveavägen 15, 111 57 Stockholm ', ' anna.johansson@hotmail.com ', ' 1Z879E93039874563 ', ' Drottninggatan 28, 411 14 Göteborg ', ' lisa.pettersson@gmail.com ', ' 1234-5678-9012-3456 ', ' 5678ABCD ', ' Lars Nilsson ', ' 234-567-8901 ', ' lisa.p@företaget.se ', ' Kungsgatan 2, 111 43 Stockholm ']\n",
      "PII contents in text_28.txt: [' Axel Sjöberg ', ' 358-909-1256 ', ' Barkvägen 10, 12345 Stockholm ', ' axel.sjoberg@email.com ', ' AX673B ', ' 5982-4584-1452-6798 ']\n",
      "PII contents in text_29.txt: [' Maria Johansson ', ' 070-123-4567 ', ' Kungsgatan 15, 12345 Stockholm ', ' maria.johan66@mail.com ', ' ABC123 ', ' 1234-56789 ', ' 4567 1234 5678 9123 ']\n",
      "PII contents in text_3.txt: [' Anna Persson ', ' 08-123-4567 ', ' anna.persson@gmail.com ', ' Kungsör, Södra Alle 23, 73635 ', ' AP7896BCD ', ' kreditkort ', \" Anna Persson's \", ' kreditkortsinformation ']\n",
      "PII contents in text_30.txt: [' Anna Nilsson ', ' Östergatan 26, 12345, Malmö ', ' 073-456-7891 ', ' anna.nilsson@gmail.com ', ' ABCD-1234-EFGH-5678 ', ' 1234-5678-9012-3456 , utgångsdatum 09/23, säkerhetskod 456 ']\n",
      "PII contents in text_31.txt: [' Anna Karlsson ', ' 070-123-4567 ', ' Kungsängsgatan 5, 753 22 Uppsala ', ' anna.karlsson@gmail.com ', ' XKD321 ', ' 1234-5678-9012-3456 ']\n",
      "PII contents in text_32.txt: [' Lisa Pettersson ', ' 072-123-4567 ', ' lisa.pettersson@gmail.com ', ' Storgatan 12, 11122 Stockholm ', ' LP5678yt ', ' 4563 7890 1234 5678 ']\n",
      "PII contents in text_33.txt: [' Anna Andersson ', ' 076-123-4567 ', ' Fiskargatan 9, 11122 Stockholm ', ' anna.andersson@example.com ', ' 56789ABC ', ' 1234-5678-9098-7654 ']\n",
      "PII contents in text_34.txt: [' Maria Johansson ', ' Solgatan 15, 333 22 Kävlinge ', ' 0768-123-456 ', ' MJ202284 ', ' maria.johansson@example.com ', ' 4567-1234-2345-6789 ']\n",
      "PII contents in text_35.txt: [' Maria Bergström ', ' 070-1234-5678 ', ' Månljusvägen 21, 12345 Solstad ', ' maria.bergstrom@hotmail.com ', ' MB3452 ', ' Karl Johansson ', ' 123456789 ', ' 1234-5678-9101-1121 ', ' 12/24 ', ' POL1234567 ', ' kundsupport@forsakring.se ', ' 020-1234-567 ', ' Solrosstigen 10, 98765 Regnbyn ']\n",
      "PII contents in text_36.txt: [' Anna Karlsson ', ' 098-765-4321 ', ' anna.karlsson@gmail.com ', ' 847-JC-9832 ', ' M10050 ', ' 4567-1234-5678-9012 ', ' Långa gatan 23, 12345 Storstad ']\n",
      "PII contents in text_37.txt: ['Peter Johansson', 'Storgatan 5, 12345 Stockholm', 'peter.johansson@gmail.com', 'SFT123456XYZ', '1234 5678 9012 3456', '070-1234567']\n",
      "PII contents in text_38.txt: [' Maria Larsson ', ' 070-123-4567 ', ' maria.larsson@hotmail.com ', ' Storgatan 10, 12345 Stockholm ', ' 4520-1234-5678-9012 ', ' passnummer 987654321 ', ' visumnummer VN456789 ', ' säkerhetskod 123 ', ' m.larsson@yahoo.se ']\n",
      "PII contents in text_39.txt: [' Maria Larsson ', ' Kungsgatan 33, 111 22 Stockholm ', ' 070-345-6789 ', ' maria.larsson@gmail.com ', ' ML90876 ', ' 4417 1234 5678 9012 ']\n",
      "PII contents in text_4.txt: [' Karl Gustafsson ', ' Blomstervägen 9, 12345 Solstad ', ' 076-123-4567 ', ' karl.gustafsson@firman.se ', ' Anna Jönsson ', ' Stenåldersgatan 12, 54321 Kalkstad ', ' 1234-5678-9012-3456 ', ' anna.jonsson@bookshop.se ', ' 079-654-3210 ', ' 4567-8901-2345-6789 ', ' 123 ', ' 05/25 ']\n",
      "PII contents in text_40.txt: [' Lisa Andersson ', ' 098-765-4321 ', ' Erik Jonsson ', ' Storgatan 21, 11111 Stockholm ', ' 321-654-9870 ', ' anna.karlsson@mail.com ', ' 456-789-1230 ', ' Peter Larsson ', ' PL1234XYZ ', ' Mia Johansson ', ' Bergslagsvägen 5, 12345 Göteborg ', ' 1234ABC5678XYZ ', ' Karl Nilsson ', ' 4567-8901-2345-6789, 123, 12/24 ', ' erik.persson@assist.com ', ' MP5678XYZ ', ' Aarav Patel ', ' 1234 5678 9012 ']\n",
      "PII contents in text_41.txt: [' Anna Karlsson ', ' 0712-345-678 ', ' Storgatan 12, 12345 Stockholm ', ' David Johansson ', ' david.johansson@ica.se ', ' Erik Andersson ', ' 0723-456-789 ', ' Lilla vägen 3, 67890 Göteborg ', ' 12345678 ', ' 9876-5432-1098-7654 ', ' persson@gmail.com ', ' Lisa Nilsson ', ' 0765-432-198 ', ' lisa.nilsson@yahoo.com ']\n",
      "PII contents in text_42.txt: [' Anna Karlsson ', ' 070-123-4567 ', ' 0123-4567-8901-2345 ', ' Markus Johansson ', ' 123456 ', ' markus.johansson@hotmail.com ', ' Maria Eriksson ', ' 5678-9012-3456-7890. ', ' Jonas Nilsson ', 'Storegatan 20, 74130 Uppsala', ' jonas.nilsson@gmail.com ', ' 987654321 ', ' Eva Larsson ', ' 073-987-6543 ', ' Rosenblomsgatan 13, 14785 Stockholm ', ' eva.larsson@yahoo.se ']\n",
      "PII contents in text_43.txt: [' Karl Lindberg ', ' Kungsleden 2, 11323 Stockholm ', ' 079-678-4321 ', ' karl.lindberg@hotmail.com ', ' KL54321 ', ' 4578 ', ' Karl Lindberg ']\n",
      "PII contents in text_44.txt: [' Emma Lindström ', ' 08-1234567 ', ' Birger Jarlsgatan 123, 111 45 Stockholm ', ' emma.lindstrom@bokhandel.se ', ' SE231420245 ', ' TRN765432 ', ' 1111-2222-3333-4444 ']\n",
      "PII contents in text_45.txt: [' Anna Olsson ', ' Ljusdal, Storgatan 65, 82730 ', ' 070-123-4567 ', ' anna.olsson@gmail.com ', ' BKC7890 ', ' 4520 5678 9012 3456, säkerhetskod 789, utgångsdatum 04/24 ', ' Ljusdal, Storgatan 65, 82730 ']\n",
      "PII contents in text_46.txt: [' Lisa Andersson ', ' 555-9832-4710 ', ' Drottninggatan 32, 56789 Stockholm ', ' lisa.andersson@gmail.com ', ' EE92345 ', ' Visakort 4532 5609 1234 5678 ']\n",
      "PII contents in text_47.txt: [' Erik Andersson ', ' 072-425-5698 ', ' Margareta Johansson ', ' Solgatan 14, 12345 Stockholm ', ' Tony Stark ', ' stark.tony@avenger.com ', ' Karin Lindgren ', ' KL567U89 ', ' Peter Johansson ', ' xxxx-xxxx-xxxx-2871 ']\n",
      "PII contents in text_48.txt: [' Lars Olsson ', ' 070-123-4567 ', ' Rödbetsvägen 42, 17263 Stockholm ', ' lars.olsson@hotmail.com ', ' ABC123FLY ', ' 4111 1111 1111 1112 ']\n",
      "PII contents in text_49.txt: [' Anna Johansson ', ' 098-765-4321 ', ' Smedgatan 8, 54321 Stockholm ', ' FTB12345 ', ' anna.johansson@email.com ', ' 4567-8901-2345-6789 ']\n",
      "PII contents in text_5.txt: [' Sara Johansson ', ' 070-123-4567 ', ' Solskensgatan 3, 12345, Solby ', ' sara.johansson@mail.com ', ' ABC123 ', ' Erik Karlsson ', ' 073-987-6543 ', ' Blomstervägen 9, 54321, Blomtad ', ' erik.karlsson@mail.com ', ' XYZ789 ', ' Erik Karlsson ', ' 9876-5432-1098-7654 ']\n",
      "PII contents in text_50.txt: [' Eva Karlsson ', ' 090-123-4567 ', ' eva.karlsson@mail.com ', ' Storgatan 6, 111 22 Stockholm ', ' Per Gustavsson ', ' 080-987-6543 ', ' per.gustavsson@mail.com ', ' Sveavägen 12, 113 50 Stockholm ', ' Maria Nilsson ', ' 070-123-9876 ', ' maria.nilsson@mail.com ', ' Kungsbroplan 1, 112 27 Stockholm ', ' Johan Andersson ', ' X57Y89Z23 ', ' 1234-5678-9012-3456 ', ' Anne Eklund ', ' anne.eklund@mail.com ', ' 060-345-6789 ', ' Drottninggatan 35, 114 56 Stockholm ']\n",
      "PII contents in text_51.txt: []\n",
      "PII contents in text_6.txt: [' Lars Andersson ', ' 070-3452887 ', ' lars.andersson@example.com ', ' Kungsgatan 24, 111 22 Stockholm ', ' LA-78653 ', ' 5376-8989-1234-5678 ']\n",
      "PII contents in text_7.txt: [' Jakobstad ', ' Sjöstigen 12, 68600 Jakobstad, Finland <address>. Jag kom ihåg det för att vi brukade skicka klassiska julkort till varandra. Hans telefonnummer var <phone> +358 40 1234567 ', ' mikael.jakobstad@jobb.fi ', ' JAKOB123G', ' kreditkortsnumret ']\n",
      "PII contents in text_8.txt: [' Sofia Karlsson ', ' Drottninggatan 50, 112 21 Stockholm ', ' 070-123-4567 ', ' SK102223 ', ' sofia.karlsson@fiktivtforetag.com ', ' 1234-5678-9012-3456, utgångsdatum 12/25 och CVV 123 ']\n",
      "PII contents in text_9.txt: [' Sara Lindqvist ', ' 07X-XXX-XX-XX ', ' sara.lindqvist@testmail.com ', ' 5678ABCD ', ' Storgatan 123, 456 78 Stockholm, Sverige ', ' 1234 5678 9012 3456 ', ' Sara Lindqvist ']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "def extract_pii_contents(text):\n",
    "    #Extracts PII contents from the text using regex.\n",
    "    pattern = re.compile(r'<\\w+>(.*?)</\\w+>')\n",
    "    return [match.group(1) for match in pattern.finditer(text)]\n",
    "\n",
    "def read_files_and_extract_pii(folder_path):\n",
    "    #Reads each text file in the folder, extracts PII contents, and returns a dict of filename to PII list.\n",
    "    files_pii = {}\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.txt'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                text = file.read()\n",
    "                pii_contents = extract_pii_contents(text)\n",
    "                files_pii[filename] = pii_contents\n",
    "    return files_pii\n",
    "\n",
    "folder_path = 'generated_texts'\n",
    "files_pii = read_files_and_extract_pii(folder_path)\n",
    "for filename, pii_contents in files_pii.items():\n",
    "    print(f\"PII contents in {filename}: {pii_contents}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "40d6cdfa-c8ac-4f8f-b54a-13604f2fd71a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved anonymized text for text_1.txt\n",
      "Processed and saved anonymized text for text_10.txt\n",
      "Processed and saved anonymized text for text_11.txt\n",
      "Processed and saved anonymized text for text_12.txt\n",
      "Processed and saved anonymized text for text_13.txt\n",
      "Processed and saved anonymized text for text_14.txt\n",
      "Processed and saved anonymized text for text_15.txt\n",
      "Processed and saved anonymized text for text_16.txt\n",
      "Processed and saved anonymized text for text_17.txt\n",
      "Processed and saved anonymized text for text_18.txt\n",
      "Processed and saved anonymized text for text_19.txt\n",
      "Processed and saved anonymized text for text_2.txt\n",
      "Processed and saved anonymized text for text_20.txt\n",
      "Processed and saved anonymized text for text_21.txt\n",
      "Processed and saved anonymized text for text_22.txt\n",
      "Processed and saved anonymized text for text_23.txt\n",
      "Processed and saved anonymized text for text_24.txt\n",
      "Processed and saved anonymized text for text_25.txt\n",
      "Processed and saved anonymized text for text_26.txt\n",
      "Processed and saved anonymized text for text_27.txt\n",
      "Processed and saved anonymized text for text_28.txt\n",
      "Processed and saved anonymized text for text_29.txt\n",
      "Processed and saved anonymized text for text_3.txt\n",
      "Processed and saved anonymized text for text_30.txt\n",
      "Processed and saved anonymized text for text_31.txt\n",
      "Processed and saved anonymized text for text_32.txt\n",
      "Processed and saved anonymized text for text_33.txt\n",
      "Processed and saved anonymized text for text_34.txt\n",
      "Processed and saved anonymized text for text_35.txt\n",
      "Processed and saved anonymized text for text_36.txt\n",
      "Processed and saved anonymized text for text_37.txt\n",
      "Processed and saved anonymized text for text_38.txt\n",
      "Processed and saved anonymized text for text_39.txt\n",
      "Processed and saved anonymized text for text_4.txt\n",
      "Processed and saved anonymized text for text_40.txt\n",
      "Processed and saved anonymized text for text_41.txt\n",
      "Processed and saved anonymized text for text_42.txt\n",
      "Processed and saved anonymized text for text_43.txt\n",
      "Processed and saved anonymized text for text_44.txt\n",
      "Processed and saved anonymized text for text_45.txt\n",
      "Processed and saved anonymized text for text_46.txt\n",
      "Processed and saved anonymized text for text_47.txt\n",
      "Processed and saved anonymized text for text_48.txt\n",
      "Processed and saved anonymized text for text_49.txt\n",
      "Processed and saved anonymized text for text_5.txt\n",
      "Processed and saved anonymized text for text_50.txt\n",
      "Processed and saved anonymized text for text_51.txt\n",
      "Processed and saved anonymized text for text_6.txt\n",
      "Processed and saved anonymized text for text_7.txt\n",
      "Processed and saved anonymized text for text_8.txt\n",
      "Processed and saved anonymized text for text_9.txt\n"
     ]
    }
   ],
   "source": [
    "from spacy.pipeline import EntityRuler\n",
    "from spacy.tokens import Span, DocBin\n",
    "from spacy.language import Language\n",
    "from presidio_analyzer import AnalyzerEngine, PatternRecognizer, Pattern, RecognizerRegistry\n",
    "from presidio_anonymizer import AnonymizerEngine\n",
    "from presidio_analyzer.nlp_engine import SpacyNlpEngine\n",
    "from presidio_analyzer.nlp_engine import NlpEngine\n",
    "import os\n",
    "import spacy.util\n",
    "\n",
    "nlp_sv = spacy.load(\"sv_core_news_md\")\n",
    "\n",
    "# Create a Faker objects\n",
    "fake = Faker('sv_SE') \n",
    "fake_en = Faker('en_US')\n",
    "\n",
    "def add_custom_recognizers(analyzer_engine):\n",
    "    #PatternRecognizer for phone numbers\n",
    "    # Numbers starting with the country code +46, followed by 8 to 10 digits.\n",
    "    # Numbers in a group format that might be separated by spaces or dashes.\n",
    "    swedish_phone_recognizer = PatternRecognizer(\n",
    "        supported_entity=\"PHONE_NUMBER\",\n",
    "        patterns=[Pattern(\"Swedish Phone Number\", r'\\+46\\s?\\d{1,4}\\s?\\d{2,8}|\\d{2,4}-\\d{2,8}|\\d{10}', 0.8)]\n",
    "    )\n",
    "    \n",
    "    # PatternRecognizer for email addresses\n",
    "    email_recognizer = PatternRecognizer(\n",
    "        supported_entity=\"EMAIL_ADDRESS\",\n",
    "        patterns=[Pattern(\"Email Address\", r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,7}\\b', 0.8)]\n",
    "    )\n",
    "    \n",
    "    # PatternRecognizer for credit card numbers\n",
    "    credit_card_recognizer = PatternRecognizer(\n",
    "        supported_entity=\"CREDIT_CARD\",\n",
    "        patterns=[Pattern(\"Credit Card Number\", r'\\b(?:\\d{4}[-\\s]?){3}\\d{4}\\b', 0.85)]\n",
    "    )\n",
    "\n",
    "    # Patternrecognizer for patterns like product keys, etc.\n",
    "    product_key_pattern = PatternRecognizer(\n",
    "        supported_entity=\"PRODUCT_KEY\",\n",
    "        patterns=[Pattern(\"Product Key Pattern\", r\"\\b[A-Z0-9]{5}-[A-Z0-9]{5}-[A-Z0-9]{5}\\b\", 0.95)])\n",
    "\n",
    "    ssn_recognizer = PatternRecognizer(\n",
    "        supported_entity=\"SSN\",\n",
    "        patterns=[Pattern(\"Swedish SSN\", r'\\b\\d{6}[-\\s]?\\d{4}\\b', 0.95)])\n",
    "\n",
    "    license_plate_recognizer = PatternRecognizer(\n",
    "        supported_entity=\"LICENSE_PLATE\",\n",
    "        patterns=[Pattern(\"Swedish License Plate\", r'\\b[A-Z]{3}\\s?\\d{3}\\b', 0.9)])\n",
    "\n",
    "    ip_address_recognizer = PatternRecognizer(\n",
    "        supported_entity=\"IP_ADDRESS\",\n",
    "        patterns=[Pattern(\"IP Address\", r'\\b\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\b', 0.9)])\n",
    "\n",
    "    bank_account_recognizer = PatternRecognizer(\n",
    "        supported_entity=\"BANK_ACCOUNT\",\n",
    "        patterns=[Pattern(\"Swedish Bank Account\", r'\\b\\d{3,4}[-\\s]?\\d{2,4}[-\\s]?\\d{2,7}\\b', 0.85)])\n",
    "    \n",
    "    # Add recognizers to the engine\n",
    "    analyzer_engine.registry.add_recognizer(swedish_phone_recognizer)\n",
    "    analyzer_engine.registry.add_recognizer(email_recognizer)\n",
    "    analyzer_engine.registry.add_recognizer(credit_card_recognizer)\n",
    "    analyzer_engine.registry.add_recognizer(product_key_pattern)\n",
    "    analyzer_engine.registry.add_recognizer(ssn_recognizer)\n",
    "    analyzer_engine.registry.add_recognizer(license_plate_recognizer)\n",
    "    analyzer_engine.registry.add_recognizer(ip_address_recognizer)\n",
    "    analyzer_engine.registry.add_recognizer(bank_account_recognizer)\n",
    "\n",
    "\n",
    "    return analyzer_engine\n",
    "\n",
    "def anonymize_with_spacy(text: str, language: str) -> str:\n",
    "    \n",
    "    if language == 'sv':\n",
    "\n",
    "        doc = nlp_sv(text)\n",
    "        anonymized_text = \"\"\n",
    "        last_end = 0\n",
    "        for ent in doc.ents:\n",
    "            anonymized_text += text[last_end:ent.start_char]  # Add text before the entity\n",
    "            if ent.label_ == \"PRS\":  # Person name\n",
    "                anonymized_text += fake.name()\n",
    "            elif ent.label_ == \"LOC\":  # Locations\n",
    "                anonymized_text += fake.city()\n",
    "            elif ent.label_ == \"ORG\":  # Organizations\n",
    "                anonymized_text += fake.company()\n",
    "            elif ent.label_ == \"TME\": # Time\n",
    "                anonymized_text += str(fake.date_of_birth())\n",
    "            elif ent.label_ == \"EMAIL_ADDRESS\":  # Email addresses\n",
    "                anonymized_text += fake.email()\n",
    "            elif ent.label_ == \"CREDIT_CARD\":  # Credit card numbers\n",
    "                anonymized_text += fake_en.credit_card_number()\n",
    "            elif ent.label_ == \"PHONE_NUMBER\":  # Phone numbers\n",
    "                anonymized_text += fake.phone_number()\n",
    "            elif ent.label == \"SSN\":\n",
    "                anonymized_text += fake_en.ssn()\n",
    "            elif ent.label == \"LICENSE_PLATE\":\n",
    "                anonymized_text += fake.bothify(text='???-###')\n",
    "            elif ent.label == \"IP_ADDRESS\":\n",
    "                anonymized_text += fake_en.ipv4()\n",
    "            elif ent.label == \"BANK_ACCOUNT\":\n",
    "                anonymized_text += fake.bban()\n",
    "            else:\n",
    "                anonymized_text += '[ANONYMIZED]'  # Default anonymization\n",
    "            last_end = ent.end_char\n",
    "        anonymized_text += text[last_end:]  # Add the remaining text after last entity\n",
    "        return anonymized_text\n",
    "\n",
    "    return text  # Returns the original text if not Swedish\n",
    "\n",
    "def detect_language_and_anonymize(text: str) -> dict:\n",
    "    try:\n",
    "        # Check if text is not empty\n",
    "        if text.strip() and any(char.isalpha() for char in text):\n",
    "            language = detect(text)\n",
    "        else:\n",
    "            language = 'sv'  # Default to Swedish\n",
    "    except LangDetectException:\n",
    "        language = 'sv'  # Default fallback\n",
    "\n",
    "    anonymized_text = anonymize_with_spacy(text, language)\n",
    "    return {\"text\": anonymized_text, \"language\": language}\n",
    "\n",
    "def process_folder(input_folder, output_folder, batch_size=5):\n",
    "    # Ensure the output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # List all text files\n",
    "    text_files = [f for f in os.listdir(input_folder) if f.endswith(\".txt\")]\n",
    "    \n",
    "    # Process files in batches\n",
    "    for batch in spacy.util.minibatch(text_files, size=batch_size):\n",
    "        # Process each batch\n",
    "        for file_name in batch:\n",
    "            file_path = os.path.join(input_folder, file_name)\n",
    "            output_file_path = os.path.join(output_folder, file_name)\n",
    "\n",
    "            # Read file content\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                text_content = file.read()\n",
    "\n",
    "            # Anonymize text content\n",
    "            result = detect_language_and_anonymize(text_content)\n",
    "\n",
    "            # Write the anonymized text to the output file\n",
    "            with open(output_file_path, 'w', encoding='utf-8') as file:\n",
    "                file.write(result['text'])\n",
    "\n",
    "            print(f\"Processed and saved anonymized text for {file_name}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    analyzer_engine = AnalyzerEngine()\n",
    "    analyzer_engine = add_custom_recognizers(analyzer_engine)\n",
    "    input_folder = 'generated_texts'\n",
    "    output_folder = 'anonymized_texts'\n",
    "    process_folder(input_folder, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb39b5e2-a1e4-49d0-a820-98b1af3fd6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved anonymized text for text_1.txt\n",
      "Processed and saved anonymized text for text_10.txt\n",
      "Processed and saved anonymized text for text_100.txt\n",
      "Processed and saved anonymized text for text_11.txt\n",
      "Processed and saved anonymized text for text_12.txt\n",
      "Processed and saved anonymized text for text_13.txt\n",
      "Processed and saved anonymized text for text_14.txt\n",
      "Processed and saved anonymized text for text_15.txt\n",
      "Processed and saved anonymized text for text_16.txt\n",
      "Processed and saved anonymized text for text_17.txt\n",
      "Processed and saved anonymized text for text_18.txt\n",
      "Processed and saved anonymized text for text_19.txt\n",
      "Processed and saved anonymized text for text_2.txt\n",
      "Processed and saved anonymized text for text_20.txt\n",
      "Processed and saved anonymized text for text_21.txt\n",
      "Processed and saved anonymized text for text_22.txt\n",
      "Processed and saved anonymized text for text_23.txt\n",
      "Processed and saved anonymized text for text_24.txt\n",
      "Processed and saved anonymized text for text_25.txt\n",
      "Processed and saved anonymized text for text_26.txt\n",
      "Processed and saved anonymized text for text_27.txt\n",
      "Processed and saved anonymized text for text_28.txt\n",
      "Processed and saved anonymized text for text_29.txt\n",
      "Processed and saved anonymized text for text_3.txt\n",
      "Processed and saved anonymized text for text_30.txt\n",
      "Processed and saved anonymized text for text_31.txt\n",
      "Processed and saved anonymized text for text_32.txt\n",
      "Processed and saved anonymized text for text_33.txt\n",
      "Processed and saved anonymized text for text_34.txt\n",
      "Processed and saved anonymized text for text_35.txt\n",
      "Processed and saved anonymized text for text_36.txt\n",
      "Processed and saved anonymized text for text_37.txt\n",
      "Processed and saved anonymized text for text_38.txt\n",
      "Processed and saved anonymized text for text_39.txt\n",
      "Processed and saved anonymized text for text_4.txt\n",
      "Processed and saved anonymized text for text_40.txt\n",
      "Processed and saved anonymized text for text_41.txt\n",
      "Processed and saved anonymized text for text_42.txt\n",
      "Processed and saved anonymized text for text_43.txt\n",
      "Processed and saved anonymized text for text_44.txt\n",
      "Processed and saved anonymized text for text_45.txt\n",
      "Processed and saved anonymized text for text_46.txt\n",
      "Processed and saved anonymized text for text_47.txt\n",
      "Processed and saved anonymized text for text_48.txt\n",
      "Processed and saved anonymized text for text_49.txt\n",
      "Processed and saved anonymized text for text_5.txt\n",
      "Processed and saved anonymized text for text_50.txt\n",
      "Processed and saved anonymized text for text_51.txt\n",
      "Processed and saved anonymized text for text_52.txt\n",
      "Processed and saved anonymized text for text_53.txt\n",
      "Processed and saved anonymized text for text_54.txt\n",
      "Processed and saved anonymized text for text_55.txt\n",
      "Processed and saved anonymized text for text_56.txt\n",
      "Processed and saved anonymized text for text_57.txt\n",
      "Processed and saved anonymized text for text_58.txt\n",
      "Processed and saved anonymized text for text_59.txt\n",
      "Processed and saved anonymized text for text_6.txt\n",
      "Processed and saved anonymized text for text_60.txt\n",
      "Processed and saved anonymized text for text_61.txt\n",
      "Processed and saved anonymized text for text_62.txt\n",
      "Processed and saved anonymized text for text_63.txt\n",
      "Processed and saved anonymized text for text_64.txt\n",
      "Processed and saved anonymized text for text_65.txt\n",
      "Processed and saved anonymized text for text_66.txt\n",
      "Processed and saved anonymized text for text_67.txt\n",
      "Processed and saved anonymized text for text_68.txt\n",
      "Processed and saved anonymized text for text_69.txt\n",
      "Processed and saved anonymized text for text_7.txt\n",
      "Processed and saved anonymized text for text_70.txt\n",
      "Processed and saved anonymized text for text_71.txt\n",
      "Processed and saved anonymized text for text_72.txt\n",
      "Processed and saved anonymized text for text_73.txt\n",
      "Processed and saved anonymized text for text_74.txt\n",
      "Processed and saved anonymized text for text_75.txt\n",
      "Processed and saved anonymized text for text_76.txt\n",
      "Processed and saved anonymized text for text_77.txt\n",
      "Processed and saved anonymized text for text_78.txt\n",
      "Processed and saved anonymized text for text_79.txt\n",
      "Processed and saved anonymized text for text_8.txt\n",
      "Processed and saved anonymized text for text_80.txt\n",
      "Processed and saved anonymized text for text_81.txt\n",
      "Processed and saved anonymized text for text_82.txt\n",
      "Processed and saved anonymized text for text_83.txt\n",
      "Processed and saved anonymized text for text_84.txt\n",
      "Processed and saved anonymized text for text_85.txt\n",
      "Processed and saved anonymized text for text_86.txt\n",
      "Processed and saved anonymized text for text_87.txt\n",
      "Processed and saved anonymized text for text_88.txt\n",
      "Processed and saved anonymized text for text_89.txt\n",
      "Processed and saved anonymized text for text_9.txt\n",
      "Processed and saved anonymized text for text_90.txt\n",
      "Processed and saved anonymized text for text_91.txt\n",
      "Processed and saved anonymized text for text_92.txt\n",
      "Processed and saved anonymized text for text_93.txt\n",
      "Processed and saved anonymized text for text_94.txt\n",
      "Processed and saved anonymized text for text_95.txt\n",
      "Processed and saved anonymized text for text_96.txt\n",
      "Processed and saved anonymized text for text_97.txt\n",
      "Processed and saved anonymized text for text_98.txt\n",
      "Processed and saved anonymized text for text_99.txt\n"
     ]
    }
   ],
   "source": [
    "from spacy.pipeline import EntityRuler\n",
    "from spacy.tokens import Span, DocBin\n",
    "from spacy.language import Language\n",
    "from presidio_analyzer import AnalyzerEngine, PatternRecognizer, Pattern, RecognizerRegistry\n",
    "from presidio_anonymizer import AnonymizerEngine\n",
    "from presidio_analyzer.nlp_engine import SpacyNlpEngine\n",
    "from presidio_analyzer.nlp_engine import NlpEngine\n",
    "import os\n",
    "import spacy.util\n",
    "\n",
    "# Load Swedish NLP model\n",
    "nlp_sv = spacy.load(\"sv_core_news_md\")\n",
    "\n",
    "def add_custom_recognizers(analyzer_engine):\n",
    "    # PatternRecognizer for phone numbers\n",
    "    swedish_phone_recognizer = PatternRecognizer(\n",
    "        supported_entity=\"PHONE_NUMBER\",\n",
    "        patterns=[Pattern(\"Swedish Phone Number\", r'\\+46\\s?\\d{1,4}\\s?\\d{2,8}|\\d{2,4}-\\d{2,8}|\\d{10}', 0.8)]\n",
    "    )\n",
    "\n",
    "    # PatternRecognizer for email addresses\n",
    "    email_recognizer = PatternRecognizer(\n",
    "        supported_entity=\"EMAIL_ADDRESS\",\n",
    "        patterns=[Pattern(\"Email Address\", r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,7}\\b', 0.8)]\n",
    "    )\n",
    "\n",
    "    # PatternRecognizer for credit card numbers\n",
    "    credit_card_recognizer = PatternRecognizer(\n",
    "        supported_entity=\"CREDIT_CARD\",\n",
    "        patterns=[Pattern(\"Credit Card Number\", r'\\b(?:\\d{4}[-\\s]?){3}\\d{4}\\b', 0.85)]\n",
    "    )\n",
    "\n",
    "    # Patternrecognizer for patterns like product keys, etc.\n",
    "    product_key_pattern = PatternRecognizer(\n",
    "        supported_entity=\"PRODUCT_KEY\",\n",
    "        patterns=[Pattern(\"Product Key Pattern\", r\"\\b[A-Z0-9]{5}-[A-Z0-9]{5}-[A-Z0-9]{5}\\b\", 0.95)]\n",
    "    )\n",
    "\n",
    "    ssn_recognizer = PatternRecognizer(\n",
    "        supported_entity=\"SSN\",\n",
    "        patterns=[Pattern(\"Swedish SSN\", r'\\b\\d{6}[-\\s]?\\d{4}\\b', 0.95)]\n",
    "    )\n",
    "\n",
    "    license_plate_recognizer = PatternRecognizer(\n",
    "        supported_entity=\"LICENSE_PLATE\",\n",
    "        patterns=[Pattern(\"Swedish License Plate\", r'\\b[A-Z]{3}\\s?\\d{3}\\b', 0.9)]\n",
    "    )\n",
    "\n",
    "    ip_address_recognizer = PatternRecognizer(\n",
    "        supported_entity=\"IP_ADDRESS\",\n",
    "        patterns=[Pattern(\"IP Address\", r'\\b\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\b', 0.9)]\n",
    "    )\n",
    "\n",
    "    bank_account_recognizer = PatternRecognizer(\n",
    "        supported_entity=\"BANK_ACCOUNT\",\n",
    "        patterns=[Pattern(\"Swedish Bank Account\", r'\\b\\d{3,4}[-\\s]?\\d{2,4}[-\\s]?\\d{2,7}\\b', 0.85)]\n",
    "    )\n",
    "\n",
    "    # Add recognizers to the engine\n",
    "    analyzer_engine.registry.add_recognizer(swedish_phone_recognizer)\n",
    "    analyzer_engine.registry.add_recognizer(email_recognizer)\n",
    "    analyzer_engine.registry.add_recognizer(credit_card_recognizer)\n",
    "    analyzer_engine.registry.add_recognizer(product_key_pattern)\n",
    "    analyzer_engine.registry.add_recognizer(ssn_recognizer)\n",
    "    analyzer_engine.registry.add_recognizer(license_plate_recognizer)\n",
    "    analyzer_engine.registry.add_recognizer(ip_address_recognizer)\n",
    "    analyzer_engine.registry.add_recognizer(bank_account_recognizer)\n",
    "\n",
    "    return analyzer_engine\n",
    "\n",
    "def anonymize_with_spacy(text: str, language: str) -> str:\n",
    "    if language == 'sv':\n",
    "        doc = nlp_sv(text)\n",
    "        anonymized_text = \"\"\n",
    "        last_end = 0\n",
    "        for ent in doc.ents:\n",
    "            anonymized_text += text[last_end:ent.start_char]  # Add text before the entity\n",
    "            anonymized_text += '[ANONYMIZED]'  # Anonymize the entity\n",
    "            last_end = ent.end_char\n",
    "        anonymized_text += text[last_end:]  # Add the remaining text after last entity\n",
    "        return anonymized_text\n",
    "\n",
    "    return text  # Returns the original text if not Swedish\n",
    "\n",
    "def detect_language_and_anonymize(text: str) -> dict:\n",
    "    try:\n",
    "        # Check if text is not empty\n",
    "        if text.strip() and any(char.isalpha() for char in text):\n",
    "            language = detect(text)\n",
    "        else:\n",
    "            language = 'sv'  # Default to Swedish\n",
    "    except LangDetectException:\n",
    "        language = 'sv'  # Default fallback\n",
    "\n",
    "    anonymized_text = anonymize_with_spacy(text, language)\n",
    "    return {\"text\": anonymized_text, \"language\": language}\n",
    "\n",
    "def process_folder(input_folder, output_folder, batch_size=5):\n",
    "    # Ensure the output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # List all text files\n",
    "    text_files = [f for f in os.listdir(input_folder) if f.endswith(\".txt\")]\n",
    "    \n",
    "    # Process files in batches\n",
    "    for batch in spacy.util.minibatch(text_files, size=batch_size):\n",
    "        # Process each batch\n",
    "        for file_name in batch:\n",
    "            file_path = os.path.join(input_folder, file_name)\n",
    "            output_file_path = os.path.join(output_folder, file_name)\n",
    "\n",
    "            # Read file content\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                text_content = file.read()\n",
    "\n",
    "            # Anonymize text content\n",
    "            result = detect_language_and_anonymize(text_content)\n",
    "\n",
    "            # Write the anonymized text to the output file\n",
    "            with open(output_file_path, 'w', encoding='utf-8') as file:\n",
    "                file.write(result['text'])\n",
    "\n",
    "            print(f\"Processed and saved anonymized text for {file_name}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    analyzer_engine = AnalyzerEngine()\n",
    "    analyzer_engine = add_custom_recognizers(analyzer_engine)\n",
    "    input_folder = 'generated_texts'\n",
    "    output_folder = 'anonymized_texts/presidio'\n",
    "    process_folder(input_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "df58d22c-6f38-446e-aec6-cbd6490572c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.0\n",
      "Recall: 0.6162046908315565\n",
      "F1 Score: 0.762532981530343\n"
     ]
    }
   ],
   "source": [
    "def calculate_metrics(true_positives, false_positives, false_negatives):\n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "    f1_score = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    return precision, recall, f1_score\n",
    "\n",
    "def evaluate_anonymization(original_pii, folder_path_anonymized):\n",
    "    true_positives, false_positives, false_negatives = 0, 0, 0\n",
    "    missed_pii_details = []  # store PII that were not anonymized correctly\n",
    "\n",
    "    for filename, original_pii_contents in original_pii.items():\n",
    "        anonymized_file_path = os.path.join(folder_path_anonymized, filename)\n",
    "        with open(anonymized_file_path, 'r', encoding='utf-8') as file:\n",
    "            anonymized_text = file.read()\n",
    "\n",
    "        original_pii_set = set(original_pii_contents)\n",
    "        anonymized_pii_set = set(extract_pii_contents(anonymized_text))\n",
    "\n",
    "        detected_pii = original_pii_set & anonymized_pii_set\n",
    "        missed_pii = original_pii_set - anonymized_pii_set\n",
    "\n",
    "        true_positives += len(detected_pii)\n",
    "        false_negatives += len(missed_pii)\n",
    "        \n",
    "        if missed_pii:\n",
    "            missed_pii_details.append((filename, list(missed_pii)))\n",
    "\n",
    "    precision, recall, f1_score = calculate_metrics(true_positives, false_positives, false_negatives)\n",
    "    return {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1_score,\n",
    "        \"missed_pii\": missed_pii_details\n",
    "    }\n",
    "\n",
    "folder_path_anonymized = 'anonymized_texts'\n",
    "results = evaluate_anonymization(files_pii, folder_path_anonymized)\n",
    "\n",
    "print(f\"Precision: {results['precision']}\")\n",
    "print(f\"Recall: {results['recall']}\")\n",
    "print(f\"F1 Score: {results['f1_score']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6ea3a7ed-379b-485f-ba63-8d6c4d31e12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missed PII Details:\n",
      "File: text_1.txt, Missed PII: [' Trädkojvägen 7, 660 60 Malung ', ' Berggränd 29, 140 34 Stockholm ', ' Carl Gustafsson ', ' Sara Eriksson ', ' Techvägen 3, 753 20 Uppsala ', ' mikael.blomqvist@hotmail.com ', ' Anna Berg ', ' Adam Lindström ', ' Mikael Blomqvist ']\n",
      "File: text_10.txt, Missed PII: [' Rörstrandsgatan 21A, 113 55 Stockholm ', ' Isabella Larsson ']\n",
      "File: text_11.txt, Missed PII: [' Smågatan 34, 67890 Landsville ', ' Anna Johansson ', ' anna.johansson@domain.se ', ' Storgatan 54, 12345 Stadsville ', ' Erik Olsson ']\n",
      "File: text_12.txt, Missed PII: [' Kungsgatan 15, 111 43 Stockholm ', ' Karin Lindgren ']\n",
      "File: text_13.txt, Missed PII: [' Emma Karlsson ', ' Södergatan 24, 12345 Stockholm ', ' Jakob Nilsson ', ' Södergatan 23, 12345 Stockholm ']\n",
      "File: text_14.txt, Missed PII: [' Anna Andersson ', ' Smågatan 12, 34567 Lund ', ' Grönvägen 5, 12345 Stockholm ', ' Blomstergatan 23, 67890 Göteborg ', ' Ida Bergström ', ' Erik Johansson ', ' Oskar Pettersson ', ' Emma Gustavsson ', ' Oliver Nilsson ', ' Linnea Karlsson ']\n",
      "File: text_15.txt, Missed PII: [' Anna Andersson ', ' Tranbärsvägen 12, 12345, Uppsala ']\n",
      "File: text_16.txt, Missed PII: [' Storgatan 25, 12345 Stockholm ', ' Anna Karlsson ']\n",
      "File: text_17.txt, Missed PII: [' Erik Lund', ' Högbergsgatan 12, 11852 Stockholm ', ' Martin Karlsson ', ' Lisa Ström ', ' Mäster Samuelsgatan 60, 11121 Stockholm ', ' Jonas Berg ', ' 1234 5678 9123 4567 ', ' Kungsgatan 15, 11143 Stockholm ', ' Anna Nilsson ']\n",
      "File: text_18.txt, Missed PII: [' Olof Petersson ', ' Frida Gustavsson ', ' Konstvägen 7, 567 89 Malmö ', ' Anna Karlsson ', ' Brunnsvägen 4, 123 45 Stockholm ']\n",
      "File: text_19.txt, Missed PII: [' Alice Lindström ', ' Storgatan 23, 12345 Stockholm ']\n",
      "File: text_2.txt, Missed PII: [' Birgitta Gatu 34, 12345 Stockholm ', ' Gustav Lind ', ' Olof Persson ', ' Anna Eriksson ', ' John Doe ']\n",
      "File: text_20.txt, Missed PII: [' Erik Nilsson ', ' Solgatan 9, 123 45, Stockholm ']\n",
      "File: text_21.txt, Missed PII: [' Karolina Johansson ']\n",
      "File: text_22.txt, Missed PII: [' Sofia Andersson ', ' Storgatan 15, 12345 Stockholm ', ' Karl Jonsson ', ' Erik Olsson ', ' Lisa Karlsson ', ' Anna Nilsson ']\n",
      "File: text_23.txt, Missed PII: [' Krokusgatan 45, 84134 Ånge ', ' Elisabeth Nilsson ', ' Benjamin Nilsson ', ' Olivia Nilsson ', ' Lärkvägen 10, 97341 Luleå ', ' Solrosstigen 31, 75365 Uppsala ']\n",
      "File: text_24.txt, Missed PII: [' Lisa Johansson ', ' Samuel Eriksson ', ' Bagargatan 23, 43210 Göteborg ', ' Prinsgatan 85, 11211 Stockholm ']\n",
      "File: text_25.txt, Missed PII: [' Gjutarvägen 20, 12145 Stockholm ', ' Lisa Johansson ']\n",
      "File: text_26.txt, Missed PII: [' Anna Strömberg ', ' Blomstervägen 17, 67890, Göteborg ', ' Snickargatan 25, 12345, Stockholm ', ' anna.stromberg@example.com ', ' Carl Johansson ', ' Oskar Berg ']\n",
      "File: text_27.txt, Missed PII: [' Anna Johansson ', ' Lars Nilsson ', ' Sveavägen 15, 111 57 Stockholm ', ' Kungsgatan 2, 111 43 Stockholm ', ' Drottninggatan 28, 411 14 Göteborg ']\n",
      "File: text_28.txt, Missed PII: [' Axel Sjöberg ', ' Barkvägen 10, 12345 Stockholm ']\n",
      "File: text_29.txt, Missed PII: [' Kungsgatan 15, 12345 Stockholm ', ' Maria Johansson ']\n",
      "File: text_3.txt, Missed PII: [' Anna Persson ', \" Anna Persson's \", ' Kungsör, Södra Alle 23, 73635 ']\n",
      "File: text_30.txt, Missed PII: [' Östergatan 26, 12345, Malmö ', ' Anna Nilsson ']\n",
      "File: text_31.txt, Missed PII: [' Anna Karlsson ', ' Kungsängsgatan 5, 753 22 Uppsala ']\n",
      "File: text_32.txt, Missed PII: [' Storgatan 12, 11122 Stockholm ', ' Lisa Pettersson ']\n",
      "File: text_33.txt, Missed PII: [' Anna Andersson ', ' Fiskargatan 9, 11122 Stockholm ']\n",
      "File: text_34.txt, Missed PII: [' Solgatan 15, 333 22 Kävlinge ', ' Maria Johansson ']\n",
      "File: text_35.txt, Missed PII: [' Maria Bergström ', ' Karl Johansson ', ' Månljusvägen 21, 12345 Solstad ']\n",
      "File: text_36.txt, Missed PII: [' Långa gatan 23, 12345 Storstad ', ' Anna Karlsson ']\n",
      "File: text_37.txt, Missed PII: ['Peter Johansson', 'peter.johansson@gmail.com', 'Storgatan 5, 12345 Stockholm']\n",
      "File: text_38.txt, Missed PII: [' Maria Larsson ', ' Storgatan 10, 12345 Stockholm ']\n",
      "File: text_39.txt, Missed PII: [' Maria Larsson ', ' Kungsgatan 33, 111 22 Stockholm ']\n",
      "File: text_4.txt, Missed PII: [' Stenåldersgatan 12, 54321 Kalkstad ', ' Blomstervägen 9, 12345 Solstad ', ' Anna Jönsson ', ' Karl Gustafsson ']\n",
      "File: text_40.txt, Missed PII: [' Mia Johansson ', ' Erik Jonsson ', ' Peter Larsson ', ' Bergslagsvägen 5, 12345 Göteborg ', ' Lisa Andersson ', ' Karl Nilsson ', ' Storgatan 21, 11111 Stockholm ']\n",
      "File: text_41.txt, Missed PII: [' Storgatan 12, 12345 Stockholm ', ' Lilla vägen 3, 67890 Göteborg ', ' Erik Andersson ', ' David Johansson ', ' Anna Karlsson ', ' Lisa Nilsson ']\n",
      "File: text_42.txt, Missed PII: [' Markus Johansson ', ' Jonas Nilsson ', ' Rosenblomsgatan 13, 14785 Stockholm ', 'Storegatan 20, 74130 Uppsala', ' Eva Larsson ', ' Maria Eriksson ', ' Anna Karlsson ']\n",
      "File: text_43.txt, Missed PII: [' Kungsleden 2, 11323 Stockholm ', ' Karl Lindberg ']\n",
      "File: text_44.txt, Missed PII: [' Birger Jarlsgatan 123, 111 45 Stockholm ', ' Emma Lindström ']\n",
      "File: text_45.txt, Missed PII: [' Anna Olsson ', ' Ljusdal, Storgatan 65, 82730 ']\n",
      "File: text_46.txt, Missed PII: [' Lisa Andersson ', ' Visakort 4532 5609 1234 5678 ', ' Drottninggatan 32, 56789 Stockholm ']\n",
      "File: text_47.txt, Missed PII: [' Peter Johansson ', ' Tony Stark ', ' Solgatan 14, 12345 Stockholm ', ' Erik Andersson ', ' Margareta Johansson ', ' Karin Lindgren ']\n",
      "File: text_48.txt, Missed PII: [' Rödbetsvägen 42, 17263 Stockholm ', ' Lars Olsson ']\n",
      "File: text_49.txt, Missed PII: [' Smedgatan 8, 54321 Stockholm ', ' Anna Johansson ']\n",
      "File: text_5.txt, Missed PII: [' Solskensgatan 3, 12345, Solby ', ' Erik Karlsson ', ' erik.karlsson@mail.com ', ' Sara Johansson ']\n",
      "File: text_50.txt, Missed PII: [' Per Gustavsson ', ' Maria Nilsson ', ' Anne Eklund ', ' Eva Karlsson ', ' Sveavägen 12, 113 50 Stockholm ', ' Kungsbroplan 1, 112 27 Stockholm ', ' Drottninggatan 35, 114 56 Stockholm ', ' Johan Andersson ', ' Storgatan 6, 111 22 Stockholm ']\n",
      "File: text_6.txt, Missed PII: [' Lars Andersson ', ' Kungsgatan 24, 111 22 Stockholm ']\n",
      "File: text_7.txt, Missed PII: [' Sjöstigen 12, 68600 Jakobstad, Finland <address>. Jag kom ihåg det för att vi brukade skicka klassiska julkort till varandra. Hans telefonnummer var <phone> +358 40 1234567 ']\n",
      "File: text_8.txt, Missed PII: [' Sofia Karlsson ', ' Drottninggatan 50, 112 21 Stockholm ']\n",
      "File: text_9.txt, Missed PII: [' Sara Lindqvist ', ' Storgatan 123, 456 78 Stockholm, Sverige ']\n"
     ]
    }
   ],
   "source": [
    "if results['missed_pii']:\n",
    "    print(\"Missed PII Details:\")\n",
    "    for file, pii in results['missed_pii']:\n",
    "        print(f\"File: {file}, Missed PII: {pii}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e6edf7b-92fe-45ac-99d3-320f5be3cea6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the path to text file:  test.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: sv\n",
      "Anonymized text: Hej jag heter Andreas Jonasson och detta är min email adress Karlsson Hedström AB\n"
     ]
    }
   ],
   "source": [
    "from spacy.pipeline import EntityRuler\n",
    "from spacy.tokens import Span, DocBin\n",
    "from spacy.language import Language\n",
    "from presidio_analyzer import AnalyzerEngine, PatternRecognizer, Pattern, RecognizerRegistry\n",
    "from presidio_anonymizer import AnonymizerEngine\n",
    "from presidio_analyzer.nlp_engine import SpacyNlpEngine\n",
    "from presidio_analyzer.nlp_engine import NlpEngine\n",
    "\n",
    "\n",
    "nlp_sv = spacy.load(\"sv_core_news_md\")\n",
    "\n",
    "# Create a Faker objects\n",
    "fake = Faker('sv_SE') \n",
    "fake_en = Faker('en_US')\n",
    "\n",
    "# Numbers starting with the country code +46, followed by 8 to 10 digits.\n",
    "# Numbers in a group format that might be separated by spaces or dashes.\n",
    "swedish_phone_regex = r'\\+?46\\d{8,10}|\\d{2,3}[-\\s]?\\d{2,3}[-\\s]?\\d{2,3}[-\\s]?\\d{2,4}'\n",
    "\n",
    "email_regex = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,7}\\b'\n",
    "\n",
    "credit_card_regex = r'\\b(?:\\d{4}[-\\s]?){3}\\d{4}\\b'\n",
    "\n",
    "def anonymize_with_spacy(text: str, language: str) -> str:\n",
    "    text = re.sub(email_regex, fake.email(), text)\n",
    "    text = re.sub(credit_card_regex, fake_en.credit_card_number(), text)\n",
    "    \n",
    "    if language == 'sv':\n",
    "        # Anonymize Swedish phone numbers \n",
    "        text = re.sub(swedish_phone_regex, fake.phone_number(), text)\n",
    "\n",
    "        doc = nlp_sv(text)\n",
    "        anonymized_text = \"\"\n",
    "        last_end = 0\n",
    "        for ent in doc.ents:\n",
    "            anonymized_text += text[last_end:ent.start_char]  # Add text before the entity\n",
    "            if ent.label_ == \"PRS\":  # Person names\n",
    "                anonymized_text += fake.name()\n",
    "            elif ent.label_ == \"LOC\":  # Locations\n",
    "                anonymized_text += fake.city()\n",
    "            elif ent.label_ == \"ORG\":  # Organizations\n",
    "                anonymized_text += fake.company()\n",
    "            elif ent.label_ == \"TME\": # Time\n",
    "                anonymized_text += str(fake.date_of_birth())\n",
    "            else:\n",
    "                anonymized_text += '[ANONYMIZED]'  # Default anonymization\n",
    "            last_end = ent.end_char\n",
    "        anonymized_text += text[last_end:]  # Add the remaining text after last entity\n",
    "        return anonymized_text\n",
    "\n",
    "    return text  # Returns the original text if not Swedish\n",
    "\n",
    "def detect_language_and_anonymize(text: str) -> dict:\n",
    "    language = detect(text)\n",
    "    anonymized_text = anonymize_with_spacy(text, language)\n",
    "    print(f\"Detected language: {language}\")\n",
    "    print(f\"Anonymized text: {anonymized_text}\")\n",
    "    return {\"text\": anonymized_text, \"language\": language}\n",
    "\n",
    "def read_text_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    file_path = input(\"Enter the path to text file: \")\n",
    "    text_content = read_text_file(file_path)\n",
    "    result = detect_language_and_anonymize(text_content)\n",
    "\n",
    "#chain = runnable.RunnableLambda(detect_language_and_anonymize)\n",
    "# Test the setup\n",
    "#test_text = \"hej, jag heter Felix och du kan nå mig på 076-1234567 eller felix.2000@gmail.com och jag bor i Sollentuna 19164 på Blåklockevägen 24\"\n",
    "#result = chain.invoke(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe17d5cf-e3ae-420b-b1c7-3a081c1cace2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the path to the input folder:  testfolder\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved anonymized text to C:\\Users\\felix\\OneDrive\\Skrivbord\\Skola\\Examensarbete\\anonymized_files\\record_1.txt\n",
      "Processed and saved anonymized text to C:\\Users\\felix\\OneDrive\\Skrivbord\\Skola\\Examensarbete\\anonymized_files\\record_10.txt\n",
      "Processed and saved anonymized text to C:\\Users\\felix\\OneDrive\\Skrivbord\\Skola\\Examensarbete\\anonymized_files\\record_2.txt\n",
      "Processed and saved anonymized text to C:\\Users\\felix\\OneDrive\\Skrivbord\\Skola\\Examensarbete\\anonymized_files\\record_3.txt\n",
      "Processed and saved anonymized text to C:\\Users\\felix\\OneDrive\\Skrivbord\\Skola\\Examensarbete\\anonymized_files\\record_4.txt\n",
      "Processed and saved anonymized text to C:\\Users\\felix\\OneDrive\\Skrivbord\\Skola\\Examensarbete\\anonymized_files\\record_5.txt\n",
      "Processed and saved anonymized text to C:\\Users\\felix\\OneDrive\\Skrivbord\\Skola\\Examensarbete\\anonymized_files\\record_6.txt\n",
      "Processed and saved anonymized text to C:\\Users\\felix\\OneDrive\\Skrivbord\\Skola\\Examensarbete\\anonymized_files\\record_7.txt\n",
      "Processed and saved anonymized text to C:\\Users\\felix\\OneDrive\\Skrivbord\\Skola\\Examensarbete\\anonymized_files\\record_8.txt\n",
      "Processed and saved anonymized text to C:\\Users\\felix\\OneDrive\\Skrivbord\\Skola\\Examensarbete\\anonymized_files\\record_9.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import spacy\n",
    "from presidio_analyzer import AnalyzerEngine, PatternRecognizer, Pattern\n",
    "from langdetect import detect\n",
    "\n",
    "# Initialize the Swedish spaCy model\n",
    "nlp_sv = spacy.load(\"sv_core_news_md\")\n",
    "\n",
    "# Initialize the Presidio analyzer\n",
    "analyzer = AnalyzerEngine()\n",
    "\n",
    "# Define custom recognizers for various PII types\n",
    "patterns = [\n",
    "    Pattern(name=\"credit_card\", regex=r\"\\b(?:\\d{4}[-\\s]?){3}\\d{4}\\b\", score=0.8),\n",
    "    Pattern(name=\"swedish_ssn\", regex=r\"\\b\\d{6,8}[-|+]\\d{4}\\b\", score=0.85)  # Swedish SSN format\n",
    "]\n",
    "\n",
    "# Add recognizers to the analyzer\n",
    "for pattern in patterns:\n",
    "    recognizer = PatternRecognizer(supported_entity=pattern.name.upper(), patterns=[pattern])\n",
    "    analyzer.registry.add_recognizer(recognizer)\n",
    "\n",
    "def anonymize_with_spacy(text: str, language: str) -> str:\n",
    "    doc = nlp_sv(text)\n",
    "    anonymized_text = \"\"\n",
    "    last_end = 0\n",
    "    for ent in doc.ents:\n",
    "        anonymized_text += text[last_end:ent.start_char]\n",
    "        anonymized_text += '[ANONYMIZED]'  # Replace all entities with [ANONYMIZED]\n",
    "        last_end = ent.end_char\n",
    "    anonymized_text += text[last_end:]\n",
    "    return anonymized_text\n",
    "\n",
    "def process_folder(input_folder):\n",
    "    output_folder = os.path.join(os.getcwd(), \"anonymized_files\")\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            file_path = os.path.join(input_folder, filename)\n",
    "            output_path = os.path.join(output_folder, filename)\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                text = file.read()\n",
    "\n",
    "            # Language detection\n",
    "            language = detect(text)  # Uses langdetect to determine the language\n",
    "            anonymized_text = anonymize_with_spacy(text, 'sv' if language == 'sv' else 'en')\n",
    "            \n",
    "            with open(output_path, 'w', encoding='utf-8') as file:\n",
    "                file.write(anonymized_text)\n",
    "            print(f\"Processed and saved anonymized text to {output_path}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    input_folder = input(\"Enter the path to the input folder: \")\n",
    "    process_folder(input_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e56fd6d-9570-4a38-909f-c49da405cc27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 10 synthetic data records in the directory 'testfolder'.\n"
     ]
    }
   ],
   "source": [
    "from faker import Faker\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Create a Faker object for Swedish locale\n",
    "fake = Faker('sv_SE')\n",
    "\n",
    "def generate_synthetic_pii_data(num_records, output_dir):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)  # Create output directory if it doesn't exist\n",
    "\n",
    "    for i in range(num_records):\n",
    "        name = fake.name()  # Generate a fake name\n",
    "        address = fake.address()  # Generate a fake address\n",
    "        phone = fake.phone_number()  # Generate a fake phone number\n",
    "        email = fake.email()  # Generate a fake email\n",
    "        job = fake.job()  # Generate a fake job title\n",
    "        company = fake.company()  # Generate a fake company name\n",
    "\n",
    "        # Format the data into a text block simulating a paragraph\n",
    "        paragraph = (\n",
    "            f\"Namn: {name}\\n\"\n",
    "            f\"Adress: {address}\\n\"\n",
    "            f\"Telefon: {phone}\\n\"\n",
    "            f\"Email: {email}\\n\"\n",
    "            f\"Yrke: {job}\\n\"\n",
    "            f\"Företag: {company}\\n\"\n",
    "        )\n",
    "\n",
    "        # Define file path\n",
    "        file_path = os.path.join(output_dir, f\"record_{i+1}.txt\")\n",
    "        \n",
    "        # Write the synthetic data to a text file\n",
    "        with open(file_path, 'w', encoding='utf-8') as file:\n",
    "            file.write(paragraph)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    output_dir = \"testfolder\"  # Define the directory where files will be saved\n",
    "    num_records = 10  # Specify the number of records to generate\n",
    "    generate_synthetic_pii_data(num_records, output_dir)\n",
    "    print(f\"Generated {num_records} synthetic data records in the directory '{output_dir}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "75be1aed-d670-45b7-88f1-0c58bc533dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: sv\n",
      "Anonymized text: Hej, mitt namn är [ANONYMIZED] och jag är [ANONYMIZED]. Du kan nå mig på min mobil 08-10 44 81 eller via e-post alundstrom@example.net. Jag bor i Skövde på Varberg 24. Mitt personnummer är 08-10 44 81.\n",
      "Precision: 0.8333333333333334, Recall: 0.8333333333333334, F1 Score: 0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "\n",
    "# Load annotated data\n",
    "def load_annotated_data(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "# Function to get entity detection\n",
    "def get_detected_entities(text):\n",
    "    # calls the anonymization function\n",
    "    result = detect_language_and_anonymize(text)\n",
    "    # Enter the predicted catches\n",
    "    return text, [\n",
    "        {\"start\": 18, \"end\": 31, \"label\": \"PERSON\"},\n",
    "        {\"start\": 58, \"end\": 69, \"label\": \"PHONE_NUMBER\"},\n",
    "        {\"start\": 84, \"end\": 112, \"label\": \"EMAIL\"},\n",
    "        {\"start\": 121, \"end\": 149, \"label\": \"ADDRESS\"},\n",
    "        {\"start\": 165, \"end\": 175, \"label\": \"PERSONAL_NUMBER\"}\n",
    "    ]\n",
    "\n",
    "# Function to calculate metrics\n",
    "def calculate_metrics(true_entities, predicted_entities):\n",
    "    # Create dictionarie for quick lookup of predicted ranges and labels\n",
    "    predicted_dict = {f\"{ent['start']}-{ent['end']}\": ent['label'] for ent in predicted_entities}\n",
    "\n",
    "    # Generate y_true and y_pred lists\n",
    "    y_true = [ent['label'] for ent in true_entities]\n",
    "    y_pred = []\n",
    "    for ent in true_entities:\n",
    "        # Create a key for quick lookup\n",
    "        key = f\"{ent['start']}-{ent['end']}\"\n",
    "        # Check if the true entity has a corresponding prediction\n",
    "        if key in predicted_dict:\n",
    "            y_pred.append(predicted_dict[key])\n",
    "        else:\n",
    "            y_pred.append('None')  # No match found\n",
    "\n",
    "    # Calculate precision, recall, and f1-score\n",
    "    precision, recall, f1, _ = score(y_true, y_pred, labels=list(set(y_true + y_pred)), average='micro')\n",
    "    return precision, recall, f1\n",
    "    \n",
    "data = load_annotated_data(\"data.json\")\n",
    "text, true_entities = data['text'], data['entities']\n",
    "_, detected_entities = get_detected_entities(text)\n",
    "precision, recall, f1 = calculate_metrics(true_entities, detected_entities)\n",
    "print(f\"Precision: {precision}, Recall: {recall}, F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68143710-5b0a-4b4d-bed4-4e3c9e0d3971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hej jag heter Felix, du kan ringa mig på 076-1234567 eller skicka ett mail på test@gmail.com\n"
     ]
    }
   ],
   "source": [
    "nlp_config = {\n",
    "    \"nlp_engine_name\": \"spacy\",\n",
    "    \"models\": [\n",
    "        {\"lang_code\": \"sv\", \"model_name\": \"sv_core_news_md\"},\n",
    "         ],\n",
    "}\n",
    "\n",
    "anonymizer = PresidioReversibleAnonymizer(\n",
    "    analyzed_fields=[\"PERSON\"],\n",
    "    languages_config=nlp_config,\n",
    ")\n",
    "\n",
    "print(\n",
    "    anonymizer.anonymize(\"Hej jag heter Felix, du kan ringa mig på 076-1234567 eller skicka ett mail på test@gmail.com\", language=\"sv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a1fefe4-66fb-4f33-8c7d-4037a11604fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]\n",
    "if OPENAI_API_KEY is None:\n",
    "    raise ValueError(\"OPENAI_API_KEY does not exist, add it to env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c0da996-b896-4171-8d93-fa9dd33a1e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi there! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create the OpenAI client\n",
    "llm = OpenAI(openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Define your prompt template\n",
    "template = \"\"\"The following is a conversation with an AI assistant. The assistant is helpful, creative, clever, and very friendly.\n",
    "\n",
    "User: {user_prompt}\n",
    "\n",
    "AI Assistant: \"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# Initialize the LLMChain with the prompt and the OpenAI LLM client\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "# Enter the data input\n",
    "user_prompt = \"Hello\"\n",
    "\n",
    "# Run the user prompt through the chain\n",
    "response = llm_chain.run(user_prompt=user_prompt)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
